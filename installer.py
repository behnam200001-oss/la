#!/usr/bin/env python3
import os
import sys
import platform
import subprocess
import importlib
import ctypes
import urllib.request
import zipfile
import tarfile
import time
import re
import json
from pathlib import Path

class AdvancedInstaller:
    def __init__(self):
        self.os_type = platform.system()
        self.arch = platform.machine()
        self.cuda_available = False
        self.opencl_available = False
        self.install_dir = Path(__file__).parent.absolute()
        self.requirements_file = self.install_dir / "requirements.txt"
        self.config_file = self.install_dir / "installer_config.json"
        self.log_file = self.install_dir / "installer.log"
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        self.config = {
            "hardware": {
                "cuda_available": False,
                "opencl_available": False,
                "cuda_version": None,
                "cudnn_version": None,
                "gpu_devices": []
            },
            "software": {
                "python_version": platform.python_version(),
                "os_type": self.os_type,
                "arch": self.arch
            },
            "installation": {
                "base_packages": [],
                "gpu_packages": [],
                "failed_packages": [],
                "install_time": None
            }
        }
        
    def log_message(self, message):
        """Ø«Ø¨Øª Ù¾ÛŒØ§Ù… Ø¯Ø± ÙØ§ÛŒÙ„ Ù„Ø§Ú¯"""
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {message}\n"
        
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_entry)
        
        print(message)
    
    def run_command(self, command, check=True, capture_output=True):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ± Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø®Ø·Ø§"""
        try:
            result = subprocess.run(
                command, 
                shell=True, 
                capture_output=capture_output, 
                text=True,
                timeout=300  # 5 minutes timeout
            )
            
            if check and result.returncode != 0:
                error_msg = f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ±: {command}\nØ®Ø±ÙˆØ¬ÛŒ Ø®Ø·Ø§: {result.stderr}"
                self.log_message(f"âŒ {error_msg}")
                return False, result.stderr
            
            return True, result.stdout
            
        except subprocess.TimeoutExpired:
            error_msg = f"Ø²Ù…Ø§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ± Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯: {command}"
            self.log_message(f"â° {error_msg}")
            return False, error_msg
        except Exception as e:
            error_msg = f"Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ± {command}: {e}"
            self.log_message(f"âŒ {error_msg}")
            return False, error_msg
    
    def check_admin_privileges(self):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø¯Ù…ÛŒÙ†"""
        try:
            if self.os_type == "Windows":
                return ctypes.windll.shell32.IsUserAnAdmin() != 0
            else:
                return os.geteuid() == 0
        except:
            return False
    
    def detect_cuda(self):
        """ØªØ´Ø®ÛŒØµ Ù¾ÛŒØ´Ø±ÙØªÙ‡ CUDA"""
        self.log_message("ğŸ” Ø¯Ø± Ø­Ø§Ù„ ØªØ´Ø®ÛŒØµ CUDA...")
        
        # Ø¨Ø±Ø±Ø³ÛŒ nvidia-smi
        success, output = self.run_command("nvidia-smi", check=False)
        if success and "NVIDIA-SMI" in output:
            self.cuda_available = True
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø³Ø®Ù‡ Ø¯Ø±Ø§ÛŒÙˆØ±
            driver_match = re.search(r"Driver Version: (\d+\.\d+)", output)
            if driver_match:
                self.config["hardware"]["driver_version"] = driver_match.group(1)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª GPU
            gpu_match = re.findall(r"(\d+MiB / \d+MiB)", output)
            if gpu_match:
                self.config["hardware"]["gpu_devices"] = gpu_match
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ CUDA
        cuda_path = os.environ.get('CUDA_PATH', '') or os.environ.get('CUDA_HOME', '')
        if cuda_path and os.path.exists(cuda_path):
            self.config["hardware"]["cuda_available"] = True
            self.config["hardware"]["cuda_path"] = cuda_path
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø³Ø®Ù‡ CUDA
            version_file = Path(cuda_path) / "version.txt"
            if version_file.exists():
                with open(version_file, 'r') as f:
                    content = f.read()
                    version_match = re.search(r"CUDA Version (\d+\.\d+\.\d+)", content)
                    if version_match:
                        self.config["hardware"]["cuda_version"] = version_match.group(1)
        
        return self.cuda_available
    
    def detect_opencl(self):
        """ØªØ´Ø®ÛŒØµ OpenCL"""
        self.log_message("ğŸ” Ø¯Ø± Ø­Ø§Ù„ ØªØ´Ø®ÛŒØµ OpenCL...")
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ clinfo
        success, output = self.run_command("clinfo", check=False)
        if success and "Platform Name" in output:
            self.opencl_available = True
            self.config["hardware"]["opencl_available"] = True
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ù„ØªÙØ±Ù…
            platform_match = re.search(r"Platform Name:\s+(.+)", output)
            if platform_match:
                self.config["hardware"]["opencl_platform"] = platform_match.group(1)
        
        return self.opencl_available
    
    def detect_hardware(self):
        """ØªØ´Ø®ÛŒØµ Ø¬Ø§Ù…Ø¹ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±"""
        self.log_message("ğŸ” Ø¯Ø± Ø­Ø§Ù„ ØªØ´Ø®ÛŒØµ Ø¬Ø§Ù…Ø¹ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±...")
        
        # ØªØ´Ø®ÛŒØµ CPU
        try:
            import cpuinfo
            info = cpuinfo.get_cpu_info()
            self.config["hardware"]["cpu"] = {
                "name": info.get("brand_raw", "Ù†Ø§Ø´Ù†Ø§Ø³"),
                "cores": os.cpu_count(),
                "arch": info.get("arch", "Ù†Ø§Ø´Ù†Ø§Ø³")
            }
        except:
            self.config["hardware"]["cpu"] = {
                "name": "Ù†Ø§Ø´Ù†Ø§Ø³",
                "cores": os.cpu_count(),
                "arch": self.arch
            }
        
        # ØªØ´Ø®ÛŒØµ Ø­Ø§ÙØ¸Ù‡
        try:
            import psutil
            mem = psutil.virtual_memory()
            self.config["hardware"]["memory"] = {
                "total": f"{mem.total / (1024**3):.1f} GB",
                "available": f"{mem.available / (1024**3):.1f} GB"
            }
        except:
            self.config["hardware"]["memory"] = {"total": "Ù†Ø§Ø´Ù†Ø§Ø³", "available": "Ù†Ø§Ø´Ù†Ø§Ø³"}
        
        # ØªØ´Ø®ÛŒØµ GPU Ùˆ Ø¯Ø±Ø§ÛŒÙˆØ±Ù‡Ø§
        self.detect_cuda()
        self.detect_opencl()
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬ ØªØ´Ø®ÛŒØµ
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, ensure_ascii=False, indent=2)
        
        return True
    
    def install_system_dependencies(self):
        """Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…"""
        self.log_message("ğŸ“¦ Ø¯Ø± Ø­Ø§Ù„ Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…...")
        
        if self.os_type == "Linux":
            # Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ø¨Ø±Ø§ÛŒ Ù„ÛŒÙ†ÙˆÚ©Ø³
            commands = [
                "apt-get update || yum update || dnf update",
                "apt-get install -y build-essential python3-dev python3-pip || "
                "yum install -y gcc python3-devel python3-pip || "
                "dnf install -y gcc python3-devel python3-pip"
            ]
            
            for cmd in commands:
                success, output = self.run_command(cmd, check=False)
                if not success:
                    self.log_message(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…: {output}")
        
        elif self.os_type == "Windows":
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ù†ØµØ¨ Build Tools Ø¨Ø±Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ²
            self.log_message("â„¹ï¸ Ø¨Ø±Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ²ØŒ Ù„Ø·ÙØ§Ù‹ Microsoft Build Tools Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯")
            self.log_message("   Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø§Ø²: https://visualstudio.microsoft.com/visual-cpp-build-tools/")
        
        return True
    
    def parse_requirements(self):
        """ØªØ¬Ø²ÛŒÙ‡ requirements.txt Ø¨Ù‡ Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ Ùˆ GPU"""
        base_packages = []
        gpu_packages = []
        
        if not self.requirements_file.exists():
            self.log_message("âŒ ÙØ§ÛŒÙ„ requirements.txt ÛŒØ§ÙØª Ù†Ø´Ø¯!")
            return False
        
        try:
            with open(self.requirements_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
                    
                    # ØªØ´Ø®ÛŒØµ Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ GPU
                    pkg_name = line.split('==')[0].split('>')[0].split('<')[0].strip().lower()
                    is_gpu_package = any(x in pkg_name for x in ['cuda', 'cupy', 'pyopencl', 'pycuda', 'tensorflow-gpu', 'torch'])
                    
                    if is_gpu_package:
                        gpu_packages.append(line)
                    else:
                        base_packages.append(line)
            
            self.config["installation"]["base_packages"] = base_packages
            self.config["installation"]["gpu_packages"] = gpu_packages
            
            return True
            
        except Exception as e:
            self.log_message(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ requirements.txt: {e}")
            return False
    
    def install_python_packages(self, packages, package_type="base"):
        """Ù†ØµØ¨ Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒØªÙˆÙ†"""
        for pkg in packages:
            self.log_message(f"ğŸ“¦ Ø¯Ø± Ø­Ø§Ù„ Ù†ØµØ¨ {pkg} ({package_type})...")
            
            # Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ± Ù†ØµØ¨
            success, output = self.run_command(f"{sys.executable} -m pip install --upgrade {pkg}")
            
            if not success:
                self.log_message(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†ØµØ¨ {pkg}: {output}")
                self.config["installation"]["failed_packages"].append(pkg)
                
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù†ØµØ¨ Ø§Ø² Ø·Ø±ÛŒÙ‚è½®æ¢ Ù…Ù†Ø§Ø¨Ø¹
                mirrors = [
                    "",
                    "-i https://pypi.org/simple/",
                    "-i https://pypi.tuna.tsinghua.edu.cn/simple/",
                    "-i https://mirrors.aliyun.com/pypi/simple/"
                ]
                
                for mirror in mirrors:
                    self.log_message(f"ğŸ”„ ØªÙ„Ø§Ø´ Ø¨Ø§ Ù…ÛŒØ±ÙˆØ± {mirror}...")
                    success, output = self.run_command(
                        f"{sys.executable} -m pip install {mirror} --upgrade {pkg}",
                        check=False
                    )
                    
                    if success:
                        self.log_message(f"âœ… {pkg} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù†ØµØ¨ Ø´Ø¯")
                        break
            else:
                self.log_message(f"âœ… {pkg} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù†ØµØ¨ Ø´Ø¯")
        
        return True
    
    def install_cuda_dependencies(self):
        """Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ CUDA"""
        if not self.cuda_available:
            self.log_message("â„¹ï¸ CUDA Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª - Ø±Ø¯ Ø´Ø¯Ù† Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ CUDA")
            return True
        
        self.log_message("ğŸ”§ Ø¯Ø± Ø­Ø§Ù„ Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ CUDA...")
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ toolkit-cuda
        if self.os_type == "Linux":
            success, output = self.run_command("which nvcc", check=False)
            if not success:
                self.log_message("â„¹ï¸ nvcc ÛŒØ§ÙØª Ù†Ø´Ø¯ - Ù†ØµØ¨ toolkit-cuda")
                self.run_command("apt-get install -y nvidia-cuda-toolkit || "
                                "yum install -y nvidia-cuda-toolkit || "
                                "dnf install -y nvidia-cuda-toolkit", check=False)
        
        return True
    
    def setup_jupyter_support(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Jupyter Lab"""
        self.log_message("ğŸ“Š Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Jupyter Lab...")
        
        # Ù†ØµØ¨ Jupyter Lab
        jupyter_packages = [
            "jupyterlab",
            "ipywidgets",
            "matplotlib",
            "seaborn",
            "pandas"
        ]
        
        self.install_python_packages(jupyter_packages, "jupyter")
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
        self.run_command(f"{sys.executable} -m ipykernel install --user --name=btc_searcher")
        
        self.log_message("âœ… Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Jupyter Lab Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
        return True
    
    def create_diagnostic_script(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„Ø§Øª"""
        diagnostic_script = self.install_dir / "diagnose.py"
        
        script_content = '''
#!/usr/bin/env python3
import sys
import platform
import subprocess
import json
from pathlib import Path

def run_command(cmd):
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=30)
        return result.returncode == 0, result.stdout, result.stderr
    except:
        return False, "", "Timeout or error"

def main():
    print("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„Ø§Øª...")
    
    # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³ÛŒØ³ØªÙ…
    print("\\n=== Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³ÛŒØ³ØªÙ… ===")
    print(f"Ø³ÛŒØ³ØªÙ… Ø¹Ø§Ù…Ù„: {platform.system()} {platform.release()}")
    print(f"Ù…Ø¹Ù…Ø§Ø±ÛŒ: {platform.machine()}")
    print(f"Ù¾Ø§ÛŒØªÙˆÙ†: {platform.python_version()}")
    
    # Ø¨Ø±Ø±Ø³ÛŒ GPU
    print("\\n=== Ø§Ø·Ù„Ø§Ø¹Ø§Øª GPU ===")
    success, output, error = run_command("nvidia-smi")
    if success:
        print("âœ… NVIDIA GPU ÛŒØ§ÙØª Ø´Ø¯")
        print(output.split('\\n')[0])  # Ø®Ø· Ø§ÙˆÙ„ Ø®Ø±ÙˆØ¬ÛŒ
    else:
        print("âŒ NVIDIA GPU ÛŒØ§ÙØª Ù†Ø´Ø¯")
    
    # Ø¨Ø±Ø±Ø³ÛŒ CUDA
    print("\\n=== ÙˆØ¶Ø¹ÛŒØª CUDA ===")
    cuda_path = None
    for env_var in ['CUDA_PATH', 'CUDA_HOME']:
        if env_var in os.environ:
            cuda_path = os.environ[env_var]
            print(f"âœ… {env_var}: {cuda_path}")
            break
    
    if not cuda_path:
        print("âŒ Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ CUDA ÛŒØ§ÙØª Ù†Ø´Ø¯")
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ú©ÛŒØ¬â€ŒÙ‡Ø§
    print("\\n=== ÙˆØ¶Ø¹ÛŒØª Ù¾Ú©ÛŒØ¬â€ŒÙ‡Ø§ ===")
    packages = ['pycuda', 'torch', 'tensorflow', 'jupyterlab']
    for pkg in packages:
        try:
            __import__(pkg)
            print(f"âœ… {pkg}: Ù†ØµØ¨ Ø´Ø¯Ù‡")
        except ImportError:
            print(f"âŒ {pkg}: Ù†ØµØ¨ Ù†Ø´Ø¯Ù‡")
    
    print("\\nâœ… ØªØ´Ø®ÛŒØµ Ú©Ø§Ù…Ù„ Ø´Ø¯")

if __name__ == "__main__":
    main()
'''
        
        with open(diagnostic_script, 'w', encoding='utf-8') as f:
            f.write(script_content)
        
        # Ø¯Ø§Ø¯Ù† Ù…Ø¬ÙˆØ² Ø§Ø¬Ø±Ø§
        diagnostic_script.chmod(0o755)
        
        self.log_message("âœ… Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„Ø§Øª Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
        self.log_message(f"   Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§: python {diagnostic_script}")
    
    def run_online_troubleshooter(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ Ø¢Ù†Ù„Ø§ÛŒÙ†"""
        self.log_message("ğŸŒ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ÛŒ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ Ø¢Ù†Ù„Ø§ÛŒÙ†...")
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø´Ú©Ù„Ø§Øª Ø±Ø§ÛŒØ¬
        common_issues = {
            "pycuda": "https://pycuda.readthedocs.io/en/latest/installation.html",
            "cuda": "https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html",
            "opencl": "https://github.com/inducer/pyopencl#installation"
        }
        
        for issue, url in common_issues.items():
            self.log_message(f"ğŸ” Ø¨Ø±Ø±Ø³ÛŒ {issue}: {url}")
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø´Ú©Ø§Ù„â€ŒØ²Ø¯Ø§ÛŒÛŒ Ø¢Ù†Ù„Ø§ÛŒÙ†
        report = {
            "system": {
                "os": self.os_type,
                "arch": self.arch,
                "python": platform.python_version()
            },
            "hardware": self.config["hardware"],
            "issues": self.config["installation"]["failed_packages"]
        }
        
        report_file = self.install_dir / "troubleshoot_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        self.log_message(f"ğŸ“ Ú¯Ø²Ø§Ø±Ø´ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {report_file}")
        self.log_message("ğŸ’¡ Ø¨Ø±Ø§ÛŒ Ú©Ù…Ú© Ø¢Ù†Ù„Ø§ÛŒÙ†ØŒ Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ø±Ø§ Ø¯Ø± Ø§Ù†Ø¬Ù…Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø¨Ù‡ Ø§Ø´ØªØ±Ø§Ú© Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯")
    
    def save_config(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ù‡Ø§ÛŒÛŒ"""
        self.config["installation"]["install_time"] = time.strftime("%Y-%m-%d %H:%M:%S")
        
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, ensure_ascii=False, indent=2)
        
        self.log_message(f"âœ… Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {self.config_file}")
    
    def run(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ù†ØµØ¨â€ŒÚ©Ù†Ù†Ø¯Ù‡"""
        self.log_message("=" * 60)
        self.log_message("ğŸ› ï¸  Ù†ØµØ¨â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Bitcoin/EVM Address Searcher")
        self.log_message("=" * 60)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø¯Ù…ÛŒÙ†
        if not self.check_admin_privileges():
            self.log_message("âš ï¸ Ø¨Ø±Ø§ÛŒ Ù†ØµØ¨ Ø¨Ø±Ø®ÛŒ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ents Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø¯Ù…ÛŒÙ† Ù†ÛŒØ§Ø² Ø¨Ø§Ø´Ø¯")
        
        # Ù…Ø±Ø­Ù„Ù‡ 1: Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ…
        self.install_system_dependencies()
        
        # Ù…Ø±Ø­Ù„Ù‡ 2: ØªØ´Ø®ÛŒØµ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±
        self.detect_hardware()
        
        # Ù…Ø±Ø­Ù„Ù‡ 3: ØªØ¬Ø²ÛŒÙ‡ requirements.txt
        if not self.parse_requirements():
            return False
        
        # Ù…Ø±Ø­Ù„Ù‡ 4: Ù†ØµØ¨ Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡
        self.install_python_packages(self.config["installation"]["base_packages"], "base")
        
        # Ù…Ø±Ø­Ù„Ù‡ 5: Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ GPU (Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯)
        if self.cuda_available:
            self.install_cuda_dependencies()
            self.install_python_packages(self.config["installation"]["gpu_packages"], "gpu")
        else:
            self.log_message("â„¹ï¸ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø± GPU ÛŒØ§ÙØª Ù†Ø´Ø¯ - Ø±Ø¯ Ø´Ø¯Ù† Ù†ØµØ¨ Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ GPU")
        
        # Ù…Ø±Ø­Ù„Ù‡ 6: Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Jupyter Lab
        self.setup_jupyter_support()
        
        # Ù…Ø±Ø­Ù„Ù‡ 7: Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ØªØ´Ø®ÛŒØµ
        self.create_diagnostic_script()
        
        # Ù…Ø±Ø­Ù„Ù‡ 8: Ø§Ø¬Ø±Ø§ÛŒ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¨Ø±Ø§ÛŒ Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚
        if self.config["installation"]["failed_packages"]:
            self.log_message("âš ï¸ Ø¨Ø±Ø®ÛŒ Ø¨Ø³ØªÙ‡â€ŒÙ‡Ø§ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù†Ø¯:")
            for pkg in self.config["installation"]["failed_packages"]:
                self.log_message(f"   âŒ {pkg}")
            
            self.run_online_troubleshooter()
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
        self.save_config()
        
        self.log_message("=" * 60)
        self.log_message("âœ… Ù†ØµØ¨ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
        self.log_message("ğŸ“– Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ú©Ø§Ø± Ø§Ø² Ø¯Ø³ØªÙˆØ± Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯:")
        self.log_message("   python main.py --help")
        self.log_message("ğŸ“Š Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Jupyter Lab:")
        self.log_message("   jupyter lab")
        self.log_message("ğŸ” Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù…Ø´Ú©Ù„Ø§Øª:")
        self.log_message("   python diagnose.py")
        self.log_message("=" * 60)
        
        return True

if __name__ == "__main__":
    installer = AdvancedInstaller()
    success = installer.run()
    sys.exit(0 if success else 1)